{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "QYYEcsc1YQL2",
        "outputId": "4d3026df-fb18-4588-972a-9f970e5fc9ee"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import drive\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Mount Google Drive\u001b[39;00m\n\u001b[1;32m      4\u001b[0m ROOT\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "#Import drive\n",
        "from google.colab import drive\n",
        "#Mount Google Drive\n",
        "ROOT=\"/content/drive\"\n",
        "drive.mount(ROOT, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dM0A4sbYMP1"
      },
      "outputs": [],
      "source": [
        "!pip install dash pandas scikit-learn plotly\n",
        "\n",
        "from dash import Dash, html, dcc, callback, Output, Input\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import plotly.express as px\n",
        "import requests\n",
        "import io\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0Oxn7wTpipb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq4gFCkFYDNQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wToBP5A6dNk9"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCqMR-S_CVu4"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_raXz4HjVlN4"
      },
      "outputs": [],
      "source": [
        "data_path = \"https://raw.githubusercontent.com/lauramauricio/election-prediction-webapp/efe5785ebf31c3bf48d528e9aa2b6ebc7fa46d29/merged_dataset.csv\"\n",
        "df = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCwKb4KyezQG"
      },
      "outputs": [],
      "source": [
        "column_drop = [\"med1\"]\n",
        "df_clean = df.drop(column_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHZPVA-LFfHJ"
      },
      "outputs": [],
      "source": [
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWj-WHE5Cb0X"
      },
      "source": [
        "# Descriptives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPV90fgu5HLk"
      },
      "outputs": [],
      "source": [
        "# Group by year and calculate the share of voter for each party\n",
        "yearly_party_share = df.groupby('year')['vdn1b'].value_counts(normalize=True).rename('share').reset_index()\n",
        "\n",
        "print(yearly_party_share)  # Display the first few rows of the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQK_qPNd6TW1"
      },
      "outputs": [],
      "source": [
        "# Filter for the \"sps/pss\" party\n",
        "sps_pss_share = yearly_party_share[yearly_party_share['vdn1b'] == 'sps/pss'][['year', 'share']]\n",
        "\n",
        "# Calculate 200 divided by 'total_gewahlt' for each year\n",
        "df['total_gewahlt_proportion'] = df['total_gewahlt']/200\n",
        "\n",
        "# Calculate the average proportion per year\n",
        "total_gewahlt_proportion_by_year = df.groupby('year')['total_gewahlt_proportion'].mean().reset_index()\n",
        "\n",
        "# Merge the party share with the total_gewahlt proportion by year\n",
        "comparison_df = pd.merge(sps_pss_share, total_gewahlt_proportion_by_year, on='year')\n",
        "comparison_df.rename(columns={'share': 'sps_pss_share', 'total_gewahlt_proportion': 'total_gewahlt_proportion'}, inplace=True)\n",
        "\n",
        "print(\"Comparison DataFrame:\")\n",
        "print(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0cK8VvtCgdr"
      },
      "source": [
        "# Transform into suitable Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV4EevAbmCER"
      },
      "outputs": [],
      "source": [
        "# Replace \"NaN\" values with 0 for both numeric and categorical data\n",
        "df_clean = df_clean.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LxJzc4-odX1"
      },
      "outputs": [],
      "source": [
        "df_clean.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz7hyDbNDqS4"
      },
      "outputs": [],
      "source": [
        "# Adjust display options to show more columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Print all column names\n",
        "print(\"Column names:\", df_clean.columns)\n",
        "\n",
        "# Print the first few rows\n",
        "print(\"First few rows:\")\n",
        "print(df_clean.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBlIZjArSxYp"
      },
      "outputs": [],
      "source": [
        "column_drop = [\"party\", \"total_gewahlt\", \"total_men\", \"total_women\", \"lr1\", \"pid2b\"]\n",
        "df_clean = df_clean.drop(column_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqNVEmhHoBZF"
      },
      "outputs": [],
      "source": [
        "# Identify categorical columns\n",
        "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Exclude 'pid2b' from categorical columns\n",
        "categorical_cols = [col for col in categorical_cols if col != 'vdn1b']\n",
        "\n",
        "# Encode categorical columns using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_clean[col] = le.fit_transform(df_clean[col].astype(str))\n",
        "    label_encoders[col] = le\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U33jsr_SmBmo"
      },
      "outputs": [],
      "source": [
        "df_clean = df_clean.drop('year', axis=1)\n",
        "df_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYlIZNwUAzZq"
      },
      "outputs": [],
      "source": [
        "df_clean[\"vdn1b\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfK9UoafTFbt"
      },
      "source": [
        "array(['sps/pss', 'no party identification', 'lps/pls', 'cvp/pdc',\n",
        "       'pda/pdt', 'rep. (& vigil.)', 'csp/pcs', 'fdp/prd', 0, 'ldu/adi',\n",
        "       'svp/udc', 'other parties', 'sd/ds', 'evp/pep', 'poch', 'fps/psl',\n",
        "       'left parties', 'gps/pes', 'fga/avf', 'right parties', 'edu/udf',\n",
        "       'sol.', 'lega', 'other comments', 'psa (psu)', 'mcg', 'bdp',\n",
        "       \"GLP/Vert'libéraux\", 'centre parties'], dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8gTWw6FCoJo"
      },
      "source": [
        "# Class Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE0Sz50gGgYL"
      },
      "outputs": [],
      "source": [
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUO3g-8kGyev"
      },
      "outputs": [],
      "source": [
        "# Convert vdn1b to a categorical text variable\n",
        "df_clean['vdn1b'] = df_clean['vdn1b'].astype('category')\n",
        "\n",
        "# Verify the conversion\n",
        "df_clean['vdn1b'].dtype  # Should show 'category'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4BlU0htItXm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dictionary to rename categories\n",
        "category_rename_mapping = {\n",
        "    0: 'unknown',  # Example for numeric 0\n",
        "    'GLP/Vert\\'libéraux': \"GLP\",\n",
        "    'bdp': 'BDP',\n",
        "    'centre parties': 'Centre Parties',\n",
        "    'csp/pcs': 'CSP',\n",
        "    'cvp/pdc': 'CVP',\n",
        "    'edu/udf': 'EDU',\n",
        "    'evp/pep': 'EVP',\n",
        "    'fdp/prd': 'FDP',\n",
        "    'fga/avf': 'FGA',\n",
        "    'fps/psl': 'FPS',\n",
        "    'gps/pes': 'GPS',\n",
        "    'ldu/adi': 'LdU',\n",
        "    'left parties': 'Left Parties',\n",
        "    'lega': 'Lega',\n",
        "    'lps/pls': 'LPS',\n",
        "    'mcg': 'MCG',\n",
        "    'other comments': 'Other Comments',\n",
        "    'other parties': 'Other Parties',\n",
        "    'pda/pdt': 'PdA',\n",
        "    'poch': 'POCH',\n",
        "    'psa (psu)': 'PSA',\n",
        "    'rep. (& vigil.)': 'Rep',\n",
        "    'right parties': 'Right Parties',\n",
        "    'sd/ds': 'SD',\n",
        "    'sol.': 'Sol',\n",
        "    'sps/pss': 'SP',\n",
        "    'svp/udc': 'SVP',\n",
        "    'voted blank': 'Voted Blank'\n",
        "}\n",
        "\n",
        "# Ensure the dictionary keys are matching the current categories\n",
        "print(\"Category rename mapping keys:\", category_rename_mapping.keys())\n",
        "\n",
        "# Rename categories\n",
        "df_clean['vdn1b'] = df_clean['vdn1b'].cat.rename_categories(category_rename_mapping)\n",
        "\n",
        "# Verify the renaming\n",
        "print(\"Renamed categories:\", df_clean['vdn1b'].cat.categories)\n",
        "print(df_clean.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4pTHrtpCz2u"
      },
      "source": [
        "## All Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6IXupoUHD6Y"
      },
      "outputs": [],
      "source": [
        "# Split the data into features and target\n",
        "X = df_clean.drop('vdn1b', axis=1)\n",
        "y = df_clean['vdn1b']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhuoJ_ysHGYc"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 2: Choose a model (Random Forest Classifier)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Step 3: Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Aj7G28mas4r"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHcJ3xO6Ax8v"
      },
      "outputs": [],
      "source": [
        "# Step 5: Save the trained model to a pickle file\n",
        "with open('random_forest_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LZ_7rygCshT"
      },
      "source": [
        "## Most Common Parties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dGuz0OvTgTP"
      },
      "outputs": [],
      "source": [
        "# Count occurrences of each party\n",
        "party_counts = df_clean['vdn1b'].value_counts()\n",
        "\n",
        "party_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53EusKpIZreA"
      },
      "outputs": [],
      "source": [
        "subset = df_clean[df_clean['vdn1b'].isin(['FDP','CVP','SP','SVP',\n",
        "                                                        'LPS','LdU','EVP','CSP',\n",
        "                                                        \"PdA\",'PSA', \"GLP\"])]\n",
        "\n",
        "subset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umiJQwRM9Ze9"
      },
      "outputs": [],
      "source": [
        "# save subset data\n",
        "subset.to_csv('subset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7YmG7dlaoNc"
      },
      "outputs": [],
      "source": [
        "# Split the data into features and target\n",
        "X = subset.drop('vdn1b', axis=1)\n",
        "y = subset['vdn1b']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_2tLalCblyc"
      },
      "outputs": [],
      "source": [
        "print(subset.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbWC6NDwbVRe"
      },
      "outputs": [],
      "source": [
        "subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqVND6ymbKB6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 2: Choose a model (Random Forest Classifier)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Step 3: Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "predictions = model.predict(X_test)\n",
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnBQsg9BKJ3G"
      },
      "source": [
        "# Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWQheu11KPAQ"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  z_clipped = np.clip(z, -500, 500)\n",
        "  s = 1 / (1 + np.exp(-z_clipped))\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMUazAaJKdyy"
      },
      "outputs": [],
      "source": [
        "def initialize_with_zeros(X):\n",
        "  num_samples, num_features = X.shape\n",
        "  weights = np.zeros(num_features).reshape(-1, 1)\n",
        "  bias = 0.0\n",
        "  assert(weights.shape == (num_features, 1))\n",
        "  assert(isinstance(bias, float) or isinstance(bias, int))\n",
        "  return weights, bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw_q1HsrKh8G"
      },
      "outputs": [],
      "source": [
        "def compute_cost(Y, y_predicted):\n",
        "  epsilon = 1e-15 # Small constant to avoid division by zero\n",
        "  num_samples = len(Y)\n",
        "  cost = (-1/num_samples) * np.sum(Y * np.log(y_predicted + epsilon) + (1 - Y) * np.log(1 - y_predicted + epsilon))\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nngWkUmoKksr"
      },
      "outputs": [],
      "source": [
        "def propagate(weights, bias, X, Y):\n",
        "  assert X.shape[0] == Y.shape[0], \"Number of samples in X and Y must match\"\n",
        "  num_samples, num_features = X.shape\n",
        "\n",
        "  linear_model = np.dot(weights.T, X.T) + bias\n",
        "  y_predicted = sigmoid(linear_model)\n",
        "  # Compute cost\n",
        "  cost = compute_cost(Y, y_predicted)\n",
        "  # BACKWARD PROPAGATION\n",
        "  dw = (1 / num_samples) * np.dot(X.T, ((y_predicted- Y.T).T))\n",
        "  db = (1 / num_samples) * np.sum(y_predicted-Y.T)\n",
        "\n",
        "  assert(dw.shape == weights.shape)\n",
        "  assert(db.dtype == float)\n",
        "  cost = np.squeeze(cost)\n",
        "  assert(cost.shape == ())\n",
        "  grads = {\"dw\": dw, \"db\": db}\n",
        "  return grads, cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD7VmVMyL6Nz"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: optimize\n",
        "\n",
        "def optimize(weights, bias, X, Y, num_iterations, learning_rate):\n",
        "    \"\"\"\n",
        "    This function optimizes w and b by running a gradient descent algorithm\n",
        "\n",
        "    Arguments:\n",
        "    weights -- weights, a numpy array of size (1, num_features)\n",
        "    bias -- bias, a scalar\n",
        "    X -- data of shape (number of examples, num_features)\n",
        "    Y -- true \"label\" vector (containing 0 if non-nith, 1 if nith), of shape (number of examples, 1)\n",
        "    num_iterations -- number of iterations of the optimization loop\n",
        "    learning_rate -- learning rate of the gradient descent update rule\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    params -- dictionary containing the weights w and bias b\n",
        "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
        "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
        "\n",
        "    Tips:\n",
        "    You basically need to write down two steps and iterate through them:\n",
        "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
        "        2) Update the parameters using gradient descent rule for w and b.\n",
        "    \"\"\"\n",
        "    costs_history=[]\n",
        "    # Gradient descent\n",
        "    for i in range(num_iterations):\n",
        "\n",
        "\n",
        "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
        "        ### START CODE HERE ###\n",
        "        grads, cost = propagate(weights,bias,X,Y)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Retrieve derivatives from grads\n",
        "        dw = np.array(grads[\"dw\"], dtype=float)\n",
        "        db =  np.array(grads[\"db\"], dtype=float)\n",
        "\n",
        "        # update rule (≈ 2 lines of code)\n",
        "        ### START CODE HERE ###\n",
        "        weights = weights.T - learning_rate * dw\n",
        "        bias -= learning_rate * db\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Record the costs\n",
        "        if i % 100 == 0:\n",
        "            costs_history.append(np.mean(cost))\n",
        "\n",
        "            # Print the cost every 100 training examples\n",
        "            print (\"Cost after iteration %i: %f\" %(i, np.mean(cost)))\n",
        "\n",
        "        weights=weights.T\n",
        "        #print(weights.shape)\n",
        "\n",
        "    params = {\"w\": weights,\n",
        "                \"b\": bias}\n",
        "\n",
        "    grads = {\"dw\": dw,\n",
        "              \"db\": db}\n",
        "\n",
        "    return params, grads, costs_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6NekVCoKtqX"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: predict\n",
        "\n",
        "def predict(weights, bias, X):\n",
        "    '''\n",
        "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
        "\n",
        "    Arguments:\n",
        "    weights -- weights, a numpy array of size (num_samples, 1)\n",
        "    bias -- bias, a scalar\n",
        "    X -- data of size (num_samples, num_features)\n",
        "\n",
        "    Returns:\n",
        "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
        "    '''\n",
        "    # Assertion for dimensions\n",
        "    #assert X.shape[1] == len(weights), \"Number of features in X must match the size of weights vector\"\n",
        "\n",
        "    linear_model = np.dot(weights, X.T) + bias\n",
        "    y_predicted = sigmoid(np.array(linear_model, dtype=float))\n",
        "    y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted[0]]\n",
        "\n",
        "    return y_predicted_cls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V062nOEMGx9"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: model\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5):\n",
        "\n",
        "    \"\"\"\n",
        "      Builds the logistic regression model by calling the function you've implemented previously\n",
        "\n",
        "      Arguments:\n",
        "      X_train -- training set represented by a numpy array of shape (num_samples_train, num_features)\n",
        "      Y_train -- training labels represented by a numpy array (vector) of shape (num_samples_train, num_features)\n",
        "      X_test -- test set represented by a numpy array of shape (num_samples_test, num_features)\n",
        "      Y_test -- test labels represented by a numpy array (vector) of shape (num_samples_test, 1)\n",
        "      num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
        "      learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
        "\n",
        "\n",
        "      Returns:\n",
        "      d -- dictionary containing information about the model.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # initialize parameters with zeros (≈ 1 line of code)\n",
        "\n",
        "    weights, bias = initialize_with_zeros(X_train)\n",
        "\n",
        "    # Gradient descent (≈ 1 line of code)\n",
        "    parameters, grads, costs_history =  optimize(weights, bias, X_train, Y_train, num_iterations, learning_rate)\n",
        "\n",
        "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
        "    weights = parameters[\"w\"]\n",
        "    bias = parameters[\"b\"]\n",
        "\n",
        "    # Predict test/train set examples (≈ 2 lines of code)\n",
        "    Y_prediction_test = predict(weights, bias, X_test)\n",
        "    Y_prediction_train = predict(weights, bias, X_train)\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Print train/test Errors\n",
        "\n",
        "    accuracy_test = np.mean(Y_prediction_test ==Y_test.reshape(1,-1))\n",
        "    print(\"Test Accuracy:\", accuracy_test)\n",
        "\n",
        "    accuracy_train = np.mean(Y_prediction_train == Y_train.reshape(1,-1))\n",
        "    print(\"Test Accuracy:\", accuracy_train)\n",
        "\n",
        "    # Plot cost over iterations\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(range(len(costs_history)), costs_history)\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Cost')\n",
        "    plt.title('Cost vs. Iterations')\n",
        "    plt.show()\n",
        "\n",
        "    d = {\"costs\": costs_history,\n",
        "        \"Y_prediction_test\": Y_prediction_test,\n",
        "        \"Y_prediction_train\" : Y_prediction_train,\n",
        "        \"w\" : weights,\n",
        "        \"b\" : bias,\n",
        "        \"learning_rate\" : learning_rate,\n",
        "        \"num_iterations\": num_iterations}\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvguCc32MKGf"
      },
      "source": [
        "# Apply to Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm8LCSshMMic"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ###\n",
        "subset['vdn1b'] = pd.Categorical(subset['vdn1b']).codes\n",
        "df_dummies_model = subset.copy()\n",
        "# Setting 'y' to 1 where it equals \"SVP\"\n",
        "df_dummies_model.loc[df_dummies_model['vdn1b'] == \"SVP\", 'vdn1b'] = 1\n",
        "df_dummies_model.loc[df_dummies_model['vdn1b'] != 1, 'vdn1b'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgsgadEmMhP-"
      },
      "outputs": [],
      "source": [
        "# train, test split\n",
        "X_train,\\\n",
        "X_test, \\\n",
        "y_train,\\\n",
        "y_test = train_test_split(df_dummies_model.iloc[:,1:], df_dummies_model['vdn1b'], test_size=0.3)\n",
        "\n",
        "# Display the shapes of the training and testing sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U8_Dl5ENbQu"
      },
      "outputs": [],
      "source": [
        "dict_data=model(X_train.values, y_train.values, X_test.values, y_test.values, num_iterations = 1000, learning_rate = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3df0Jwu1YkD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Extract predictions from the dictionary\n",
        "y_pred = dict_data['predictions']\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX8tqSPI1Mxl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load your data (replace with your own data loading code)\n",
        "# data = pd.read_csv('your_dataset.csv')\n",
        "# X = data.drop('target', axis=1)\n",
        "# y = data['target']\n",
        "\n",
        "# Example data (for demonstration purposes)\n",
        "X, y = np.random.rand(43000, 10), np.random.randint(2, size=43000)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Random Forest metrics\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_precision = precision_score(y_test, y_pred_rf)\n",
        "rf_recall = recall_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf)\n",
        "rf_auc = roc_auc_score(y_test, y_pred_rf)\n",
        "\n",
        "# Train and evaluate Neural Network\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "y_pred_nn = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Neural Network metrics\n",
        "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
        "nn_precision = precision_score(y_test, y_pred_nn)\n",
        "nn_recall = recall_score(y_test, y_pred_nn)\n",
        "nn_f1 = f1_score(y_test, y_pred_nn)\n",
        "nn_auc = roc_auc_score(y_test, y_pred_nn)\n",
        "\n",
        "# Compare Metrics\n",
        "metrics = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'],\n",
        "    'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_f1, rf_auc],\n",
        "    'Neural Network': [nn_accuracy, nn_precision, nn_recall, nn_f1, nn_auc]\n",
        "})\n",
        "\n",
        "print(metrics)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
